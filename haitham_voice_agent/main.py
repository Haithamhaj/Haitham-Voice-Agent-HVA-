"""
Haitham Voice Agent - Main Entry Point

Fully Local Voice System:
- Local STT (Whisper)
- Local TTS (macOS Say)
- Command Mode (Interactive)
- Session Mode (Long Recordings)
"""

import asyncio
import logging
import sys
import json
import argparse
from pathlib import Path
from typing import Optional

from haitham_voice_agent.config import Config
from haitham_voice_agent.tools.voice import LocalSTT, TTS, SessionRecorder, init_whisper_models
from haitham_voice_agent.llm_router import LLMRouter
from haitham_voice_agent.model_router import TaskMeta, choose_model
from haitham_voice_agent.tools.gemini.gemini_router import choose_gemini_variant
from haitham_voice_agent.tools.memory.voice_tools import VoiceMemoryTools
from haitham_voice_agent.tools.gmail.connection_manager import ConnectionManager

# Set up logging
logging.basicConfig(
    level=getattr(logging, Config.LOG_LEVEL),
    format=Config.LOG_FORMAT,
    handlers=[
        logging.FileHandler(Config.LOG_FILE),
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)


from haitham_voice_agent.tools.stt_router import transcribe_command, transcribe_session
from haitham_voice_agent.intent_router import route_command
from haitham_voice_agent.tools.arabic_normalizer import normalize_arabic_text
from haitham_voice_agent.tools.tasks.task_manager import task_manager
from haitham_voice_agent.tools.files import FileTools
from haitham_voice_agent.tools.system_tools import SystemTools
from haitham_voice_agent.tools.smart_organizer import get_organizer
from haitham_voice_agent.tools.secretary import get_secretary
from haitham_voice_agent.tools.advisor import get_advisor
from haitham_voice_agent.memory.manager import get_memory_manager

def validate_config() -> bool:
    """Validates the application configuration."""
    if not Config.validate():
        logger.error("Configuration validation failed.")
        return False
    return True

        logger.warning(f"‚ö†Ô∏è FOUND LEGACY GEMINI REFERENCES IN: {found_files}")
        # We won't crash, just warn, as it might be in comments
    else:
        logger.info("‚úÖ No legacy Gemini 1.5 references found.")


class HVA:
    """Haitham Voice Agent - Main Orchestrator"""
    
    def __init__(self):
        logger.info("=" * 60)
        logger.info(f"Initializing HVA v{Config.HVA_VERSION}")
        logger.info("=" * 60)
        
        # 1. Initialize Configuration
        if not validate_config():
            raise RuntimeError("Configuration validation failed")
        
        # Initialize Gemini mapping
        Config.init_gemini_mapping()
        
        # Initialize Whisper models
        logger.info("Initializing Whisper models...")
        init_whisper_models()
        
        # Initialize voice components
        self.stt = LocalSTT()
        self.tts = TTS()
        self.recorder = SessionRecorder()
        
        # Initialize LLM
        self.llm_router = LLMRouter()
        
        # Initialize tools
        self.memory_tools = VoiceMemoryTools()
        self.gmail = ConnectionManager()
        self.file_tools = FileTools()
        self.system_tools = SystemTools()
        
        # State
        self.language = "ar"  # Default language
        self.is_running = True
        
        logger.info("HVA initialized successfully")
    
    async def initialize_async(self):
        """Initialize async components"""
        await self.memory_tools.ensure_initialized()
        logger.info("Async components initialized")
    
    def speak(self, text: str):
        """Speak text using TTS"""
        self.tts.speak(text, language=self.language)
    
    async def process_command_mode(self):
        """
        Command Mode: Listen -> Route -> Execute
        """
        # Capture Audio
        capture = self.stt.capture_audio()
        if not capture:
            return
            
        audio_bytes, duration = capture
        
        # Check for long speech (treat as note)
        strict_config = getattr(Config, "STT_STRICT_CONFIG", {"max_realtime_seconds": 10.0})
        if duration > strict_config["max_realtime_seconds"]:
            logger.info(f"Long speech detected ({duration:.2f}s). Treating as memory note.")
            
            # Use session transcriber for better quality on long audio
            text = transcribe_session(audio_bytes, duration)
            
            if text:
                self.speak("ÿ™ŸÖ ÿ≠ŸÅÿ∏ ÿßŸÑÿ¨ŸÑÿ≥ÿ© ŸÉŸÖŸÑÿßÿ≠ÿ∏ÿ© ÿ∑ŸàŸäŸÑÿ©" if self.language == "ar" else "Long session saved as note")
                await self.memory_tools.process_voice_note(text)
            else:
                self.speak("ŸÖÿß ŸÇÿØÿ±ÿ™ ÿ£ŸÅÿ±ÿ∫ ÿßŸÑÿ¨ŸÑÿ≥ÿ© ÿ®ÿ¥ŸÉŸÑ Ÿàÿßÿ∂ÿ≠." if self.language == "ar" else "Could not transcribe session clearly.")
            return

        # Short Command
        text = transcribe_command(audio_bytes, duration)
        
        if not text:
            # Validation failed or garbage
            logger.info("STT returned None (unreliable speech). Asking user to repeat.")
            self.speak("ŸÖÿß ŸÅŸáŸÖÿ™ ŸÉŸÑÿßŸÖŸÉÿå ÿ≠ÿßŸàŸÑ ÿ™ÿπŸäÿØ ÿßŸÑÿ¨ŸÖŸÑÿ© ÿ®ÿµŸàÿ™ ÿ£Ÿàÿ∂ÿ≠ Ÿàÿ£ŸÇÿµÿ±." if self.language == "ar" else "I didn't understand, please repeat clearly.")
            return

        logger.info(f"Command (Raw): {text}")
        
        # Normalize if Arabic
        if self.language == "ar":
            text = await normalize_arabic_text(text, mode="command")
            logger.info(f"Command (Normalized): {text}")
            
        await self.process_text_command(text)

    async def process_text_command(self, text: str):
        """
        Process a text command (Route -> Execute)
        """
        # 1. Deterministic Routing (Fast Path)
        intent = route_command(text)
        
        if intent["confidence"] > 0.7:
            logger.info(f"Deterministic intent matched: {intent['action']}")
            
            # Execute directly
            if intent["action"] == "start_session_recording":
                await self.start_session_mode()
                return
                
            elif intent["action"] == "stop_session_recording":
                # Should not happen in command mode usually, but handle it
                self.speak("ŸÑÿß ŸäŸàÿ¨ÿØ ÿ¨ŸÑÿ≥ÿ© ŸÜÿ¥ÿ∑ÿ©" if self.language == "ar" else "No active session")
                return
                
            elif intent["action"] == "save_memory_note":
                content = intent["params"].get("content", text)
                await self.memory_tools.process_voice_note(content)
                self.speak("ÿ™ŸÖ ÿßŸÑÿ≠ŸÅÿ∏" if self.language == "ar" else "Saved")
                return
                
            elif intent["action"] == "fetch_latest_email":
                email = self.gmail.fetch_latest_email()
                if email:
                    self.speak(f"ÿ•ŸäŸÖŸäŸÑ ŸÖŸÜ {email['from']}: {email['subject']}" if self.language == "ar" else f"Email from {email['from']}: {email['subject']}")
                else:
                    self.speak("ŸÑÿß ŸäŸàÿ¨ÿØ ÿ•ŸäŸÖŸäŸÑÿßÿ™ ÿ¨ÿØŸäÿØÿ©" if self.language == "ar" else "No new emails")
                return
                
            elif intent["action"] == "summarize_latest_email":
                # Fallback to planner for complex tasks
                pass 
                
            elif intent["action"] == "beautify_transcript":
                # On-demand normalization
                self.speak("ÿ¨ÿßÿ±Ÿä ÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑŸÜÿµ..." if self.language == "ar" else "Beautifying transcript...")
                # We assume the user wants to beautify the LAST session or note.
                # For now, let's just beautify the current text command if it was long, 
                # OR we need to fetch the last memory.
                # Given the prompt, let's just say we support it but maybe need a target.
                # If this was a voice command "beautify this", "this" is the command itself which is short.
                # Realistically, this would apply to a stored memory.
                # Let's implement a simple version that fetches the last voice note.
                last_note = await self.memory_tools.get_last_voice_note()
                if last_note:
                    normalized = await normalize_arabic_text(last_note, mode="session") # Force session mode for length
                    self.speak("ÿßŸÑŸÜÿµ ÿßŸÑŸÖÿ≠ÿ≥ŸÜ:" if self.language == "ar" else "Beautified text:")
                    print(f"\n--- Beautified Transcript ---\n{normalized}\n-----------------------------")
                    # Optionally update the memory
                else:
                    self.speak("ŸÑÿß ŸäŸàÿ¨ÿØ ŸÖŸÑÿßÿ≠ÿ∏ÿßÿ™ ÿ≥ÿßÿ®ŸÇÿ©" if self.language == "ar" else "No previous notes")
                return 

            elif intent["action"] == "create_task":
                # Extract title from text (simple heuristic: everything after "add task" or similar)
                # For now, just use the whole text or ask LLM to parse. 
                # Let's use the planner to extract details properly if confidence is high but params are missing.
                # But since we are in deterministic block, we might not have params.
                # Let's fall through to planner for extraction OR do simple extraction here.
                # Simple extraction:
                pass # Fall through to planner to extract title/project/date

            elif intent["action"] == "list_tasks":
                tasks = task_manager.list_tasks(status="open")
                if not tasks:
                    self.speak("ŸÑÿß ŸäŸàÿ¨ÿØ ŸÖŸáÿßŸÖ ŸÖŸÅÿ™Ÿàÿ≠ÿ©" if self.language == "ar" else "No open tasks")
                else:
                    count = len(tasks)
                    self.speak(f"ŸÑÿØŸäŸÉ {count} ŸÖŸáÿßŸÖ ŸÖŸÅÿ™Ÿàÿ≠ÿ©." if self.language == "ar" else f"You have {count} open tasks.")
                    # List first 3
                    for t in tasks[:3]:
                        self.speak(f"- {t.title}")
                return
        
            elif intent["action"] == "search_notes":
                # Default search for "last notes" or just general listing
                # We can search for "*" or just fetch recent
                # For now, let's search for "note" or "ŸÖŸÑÿßÿ≠ÿ∏ÿ©" to get everything, or rely on empty query if supported
                # But search_memories usually needs a query.
                # Let's assume the user wants recent notes.
                query = "recent" # The memory system might not support this keyword specially, but let's try or use empty
                # Actually, let's just use the text itself as query if it's specific, or "note" if generic
                res = await self.memory_tools.search_memory_voice("note", language=self.language)
                self.speak(res)
                return

        # 2. LLM Routing (Fallback / Complex Tasks)
        # Route & Plan
        plan = await self.plan_command(text)
        
        # Fallback: If LLM failed to identify intent but it looks like a note
        if (plan.get("intent") in ["Unknown", "unknown_action", None] or plan.get("action") == "unknown") and self._looks_like_note(text):
             logger.info("Fallback intent: treating unknown text as save_memory_note")
             plan = {
                 "intent": "Save Note (Fallback)",
                 "tool": "memory",
                 "action": "save_note",
                 "parameters": {"content": text},
                 "confirmation_needed": False
             }
        
        # Confirm
        if plan.get("confirmation_needed", True):
            if not self.confirm_plan(plan):
                self.speak("ÿ™ŸÖ ÿßŸÑÿ•ŸÑÿ∫ÿßÿ°" if self.language == "ar" else "Cancelled")
                return
        
        # Execute
        result = await self.execute_plan(plan)
        
        # Respond
        self._speak_result(result)

    def _is_session_start_trigger(self, text: str) -> bool:
        """Check if command triggers session mode"""
        triggers_ar = ["ÿßÿ®ÿØÿ£ ÿ¨ŸÑÿ≥ÿ©", "ÿ™ÿ≥ÿ¨ŸäŸÑ ÿßÿ¨ÿ™ŸÖÿßÿπ", "ÿßÿ®ÿØÿ£ ÿßŸÑÿßÿ¨ÿ™ŸÖÿßÿπ", "ÿ≥ÿ¨ŸÑ ÿ¨ŸÑÿ≥ÿ©"]
        triggers_en = ["start session", "record meeting", "start meeting", "record session"]
        
        text_lower = text.lower()
        triggers = triggers_ar if self.language == "ar" else triggers_en
        return any(t in text_lower for t in triggers)

    def _looks_like_note(self, text: str) -> bool:
        """Check if text looks like a note (fallback heuristic)"""
        if not text:
            return False

        # Long-enough natural speech (either AR or EN)
        if len(text) < 20:
            return False

        # If it contains time or date words, treat as note if nothing else matched
        note_markers = ["ŸÖŸÑÿßÿ≠ÿ∏ÿ©", "meeting", "ÿßÿ¨ÿ™ŸÖÿßÿπ", "ŸÖŸàÿπÿØ", "idea", "ŸÅŸÉÿ±ÿ©", "ÿ®ÿÆÿµŸàÿµ"]
        if any(marker in text for marker in note_markers):
            return True

        # Fallback: if it's long Arabic text and not clearly a question/command, treat as note
        import re
        has_arabic = re.search(r"[\u0600-\u06FF]", text) is not None
        if has_arabic and text.count("ÿü") == 0:
            return True

        return False

    def _resolve_path(self, path_name: str) -> str:
        """Resolve spoken path name to actual path"""
        if not path_name:
            return "~"
            
        name = path_name.lower().strip()
        
        # Common mappings
        mappings = {
            "development": "~/development",
            "ÿØŸäŸÅŸàŸÑŸàÿ®ŸÖŸÜÿ™": "~/development",
            "ÿ™ÿ∑ŸàŸäÿ±": "~/development",
            "downloads": "~/Downloads",
            "ÿ™ŸÜÿ≤ŸäŸÑÿßÿ™": "~/Downloads",
            "documents": "~/Documents",
            "ŸÖÿ≥ÿ™ŸÜÿØÿßÿ™": "~/Documents",
            "desktop": "~/Desktop",
            "ÿ≥ÿ∑ÿ≠ ÿßŸÑŸÖŸÉÿ™ÿ®": "~/Desktop",
            "home": "~",
            "ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿäÿ©": "~",
            "haitham": "~",
            "ŸáŸäÿ´ŸÖ": "~",
            "ŸáŸäŸéŸÖ": "~",
            "ŸáŸäÿ∞ÿßŸÖ": "~",
            "root": "/",
            "projects": "~/HVA_Workspace/projects",
            "ŸÖÿ¥ÿßÿ±Ÿäÿπ": "~/HVA_Workspace/projects"
        }
        
        # Check exact match
        if name in mappings:
            return mappings[name]
            
        # Check partial match (e.g. "file development")
        for key, val in mappings.items():
            if key in name:
                return val
                
        # Default to home if unknown, or try to use as is relative to home
        # If it looks like a path, use it
        if "/" in name:
            return name
            
        # Fallback: assume it's a folder in home
        return f"~/{path_name}"

    async def start_session_mode(self):
        """
        Session Mode: Record -> Transcribe -> Analyze
        """
        logger.info("Starting Session Mode")
        self.speak("ÿ®ÿØÿ£ÿ™ ÿßŸÑÿ™ÿ≥ÿ¨ŸäŸÑ. ŸÇŸÑ 'ÿ•ŸäŸÇÿßŸÅ ÿßŸÑÿ™ÿ≥ÿ¨ŸäŸÑ' ÿπŸÜÿØ ÿßŸÑÿßŸÜÿ™Ÿáÿßÿ°." if self.language == "ar" else "Recording started. Say 'Stop Recording' when done.")
        
        # Start recording
        session_path = self.recorder.start()
        
        # Wait for stop command
        while self.recorder.is_recording():
            # Listen for stop command periodically
            # We use a short timeout check to allow the loop to continue if silence
            # Note: In a real concurrent system, we might need a separate listening thread
            # For now, we'll block on listen_realtime which uses VAD. 
            # If user speaks, we check if it's "stop".
            
            # NOTE: Since we are recording raw audio in background, 
            # we can't easily use the SAME mic for VAD without conflict on some systems.
            # However, speech_recognition + pyaudio might conflict.
            # A robust way is to rely on a keyboard interrupt or a specific silence duration.
            # For this implementation, we will assume the user presses Ctrl+C or we implement
            # a simple check if we can.
            
            # LIMITATION: Simultaneous recording and listening is hard with single mic.
            # Strategy: We will just record until KeyboardInterrupt OR 
            # we can't listen while recording.
            # Let's use a blocking input for "Press Enter to stop" as a fallback for CLI
            # or rely on the user stopping via a separate signal.
            
            # For this CLI version, let's use a non-blocking check or just wait for user input
            print(">> Press ENTER to stop recording <<")
            await asyncio.get_event_loop().run_in_executor(None, sys.stdin.readline)
            break
            
        # Stop recording
        final_path = self.recorder.stop()
        self.speak("ÿ™ŸÖ ÿ•ŸäŸÇÿßŸÅ ÿßŸÑÿ™ÿ≥ÿ¨ŸäŸÑ. ÿ¨ÿßÿ±Ÿä ÿßŸÑŸÖÿπÿßŸÑÿ¨ÿ©..." if self.language == "ar" else "Recording stopped. Processing...")
        
        # Transcribe
        # Read file to bytes
        try:
            with open(final_path, "rb") as f:
                audio_bytes = f.read()
                
            # Calculate duration roughly (optional, or pass 0 if not needed by router logic except for logging)
            # We can get duration from file size / rate
            # Wav file header has size, but let's just pass 0 or estimate
            # Or use soundfile to get duration
            import soundfile as sf
            info = sf.info(final_path)
            duration = info.duration
            
            transcript = transcribe_session(audio_bytes, duration)
            
        except Exception as e:
            logger.error(f"Failed to read session file: {e}")
            transcript = None

        logger.info(f"Transcript length: {len(transcript) if transcript else 0}")
        
        if not transcript:
            logger.info("Session STT failed or was too noisy.")
            self.speak("ŸÖÿß ŸÇÿØÿ±ÿ™ ÿ£ŸÅÿ±ÿ∫ ÿßŸÑÿ¨ŸÑÿ≥ÿ© ÿ®ÿ¥ŸÉŸÑ Ÿàÿßÿ∂ÿ≠. ÿ≠ÿßŸàŸÑ ÿ™ÿπŸäÿØ ÿßŸÑÿ™ÿ≥ÿ¨ŸäŸÑ ŸÅŸä ŸÖŸÉÿßŸÜ ÿ£ŸáÿØÿ£." if self.language == "ar" else "Could not transcribe session clearly. Please try again in a quieter place.")
            return

        # Analyze Session
        await self.analyze_session(transcript)

    async def analyze_session(self, transcript: str):
        """Analyze session transcript using Gemini"""
        # 1. Build TaskMeta for Router
        meta = TaskMeta(
            context_tokens=len(transcript) // 4,  # Rough estimate
            task_type="doc_analysis",
            risk="medium",
            latency="background",
            is_document=True
        )
        
        # 2. Choose Model (Gemini)
        gemini_decision = choose_gemini_variant(meta)
        model_name = Config.resolve_gemini_model(gemini_decision["logical_model"])
        
        logger.info(f"Analyzing session with {model_name}")
        
        # 3. Generate Analysis
        prompt = f"""
Analyze this session transcript:

{transcript}

Provide:
1. Executive Summary (3-5 sentences)
2. Key Decisions
3. Action Items

Output format: JSON
"""
        # Call LLM (using router's generic method, but targeting Gemini)
        # We need to ensure we use the specific model. 
        # The LLMRouter currently defaults to config.GEMINI_MODEL.
        # We should ideally pass the model name, but LLMRouter.generate_with_gemini 
        # uses the configured default. For now, that's fine as it maps to Pro.
        
        analysis = await self.llm_router.generate_with_gemini(prompt)
        
        # 4. Save to Memory
        await self.memory_tools.process_voice_note(
            f"Session Analysis:\n{analysis}\n\nTranscript:\n{transcript[:1000]}..."
        )
        
        self.speak("ÿ™ŸÖ ÿ≠ŸÅÿ∏ ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿ¨ŸÑÿ≥ÿ© ŸÅŸä ÿßŸÑÿ∞ÿßŸÉÿ±ÿ©" if self.language == "ar" else "Session analysis saved to memory")

    async def plan_command(self, text: str) -> dict:
        """Generate execution plan using Hybrid Intelligence (Ollama -> GPT)"""
        
        # --- 1. Ollama Orchestrator (Local Intelligence) ---
        from haitham_voice_agent.ollama_orchestrator import get_orchestrator
        orchestrator = get_orchestrator()
        
        classification = await orchestrator.classify_request(text)
        
        if classification.get("type") == "direct_response":
            logger.info("Ollama handled request directly.")
            return {
                "intent": "Direct Response",
                "tool": "system",
                "action": "speak",
                "parameters": {"text": classification["response"]},
                "confirmation_needed": False
            }
            
        elif classification.get("type") == "execute_command":
            logger.info(f"Ollama identified command: {classification['intent']}")
            return {
                "intent": classification["intent"],
                "tool": "system", # Or map to specific tool if possible
                "action": classification["intent"],
                "parameters": classification.get("parameters", {}),
                "confirmation_needed": False
            }
            
        # If delegate, we continue to GPT/Gemini as usual
        logger.info(f"Ollama delegated to: {classification.get('delegate_to')} ({classification.get('reason')})")
        
        # --- 2. Cloud Intelligence (GPT/Gemini) ---
        
        # Build TaskMeta
        meta = TaskMeta(
            context_tokens=len(text) // 4,
            task_type="planning",
            risk="low",
            latency="interactive"
        )
        
        # Choose Model
        decision = choose_model(meta)
        model_name = Config.resolve_model(decision["model"])
        
        prompt = f"""
ÿ£ŸÜÿ™ ÿßŸÑÿØŸÖÿßÿ∫ ÿßŸÑÿ∞ŸÉŸä ŸÑŸÖÿ≥ÿßÿπÿØ ŸáŸäÿ´ŸÖ ÿßŸÑÿµŸàÿ™Ÿä (HVA).
ŸÖŸáŸÖÿ™ŸÉ ŸÅŸáŸÖ ŸÜŸäÿ© ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ Ÿàÿ™ÿ≠ŸàŸäŸÑŸáÿß ÿ•ŸÑŸâ ÿ£ÿØÿßÿ© Ÿàÿ•ÿ¨ÿ±ÿßÿ° ŸÖÿ≠ÿØÿØ.

ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ŸÇÿßŸÑ: "{text}"

# ÿßŸÑÿ£ÿØŸàÿßÿ™ ÿßŸÑŸÖÿ™ÿßÿ≠ÿ©:

## 1. memory (ÿßŸÑÿ∞ÿßŸÉÿ±ÿ©)
- save_note: ÿ≠ŸÅÿ∏ ŸÖŸÑÿßÿ≠ÿ∏ÿ© ÿ£Ÿà ŸÅŸÉÿ±ÿ© ÿ£Ÿà ŸÖÿπŸÑŸàŸÖÿ©
- search: ÿßŸÑÿ®ÿ≠ÿ´ ŸÅŸä ÿßŸÑŸÖŸÑÿßÿ≠ÿ∏ÿßÿ™ ÿßŸÑŸÖÿ≠ŸÅŸàÿ∏ÿ©
- ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑÿØÿßŸÑÿ©: "ÿßÿ≠ŸÅÿ∏"ÿå "ÿ≥ÿ¨ŸëŸÑ"ÿå "ÿ™ÿ∞ŸÉŸëÿ±"ÿå "ŸÅŸÉÿ±ÿ©"ÿå "ŸÖŸÑÿßÿ≠ÿ∏ÿ©"ÿå "ÿßÿ®ÿ≠ÿ´ ŸÅŸä ŸÖŸÑÿßÿ≠ÿ∏ÿßÿ™Ÿä"

## 2. files (ÿßŸÑŸÖŸÑŸÅÿßÿ™)
- list_files: ÿπÿ±ÿ∂ ÿßŸÑŸÖŸÑŸÅÿßÿ™ ŸÅŸä ŸÖÿ¨ŸÑÿØ
- search_files: ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÜ ŸÖŸÑŸÅ ŸÖÿπŸäŸÜ
- create_folder: ÿ•ŸÜÿ¥ÿßÿ° ŸÖÿ¨ŸÑÿØ ÿ¨ÿØŸäÿØ ‚¨ÖÔ∏è ŸÖŸáŸÖ!
- ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑÿØÿßŸÑÿ©: "ÿßŸÅÿ™ÿ≠ ŸÖÿ¨ŸÑÿØ"ÿå "ÿ£ŸÜÿ¥ÿ¶ ŸÖÿ¨ŸÑÿØ"ÿå "ÿßÿµŸÜÿπ ŸÖÿ¨ŸÑÿØ"ÿå "ŸÖÿ¨ŸÑÿØ ÿ¨ÿØŸäÿØ"ÿå "ÿßÿπÿ±ÿ∂ ÿßŸÑŸÖŸÑŸÅÿßÿ™"

## 3. gmail (ÿßŸÑÿ®ÿ±ŸäÿØ)
- fetch_email: ŸÇÿ±ÿßÿ°ÿ© ÿ¢ÿÆÿ± ÿ®ÿ±ŸäÿØ ÿ•ŸÑŸÉÿ™ÿ±ŸàŸÜŸä
- search_email: ÿßŸÑÿ®ÿ≠ÿ´ ŸÅŸä ÿßŸÑÿ®ÿ±ŸäÿØ
- create_draft: ÿ•ŸÜÿ¥ÿßÿ° ŸÖÿ≥ŸàÿØÿ©
- ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑÿØÿßŸÑÿ©: "ÿ•ŸäŸÖŸäŸÑ"ÿå "ÿ®ÿ±ŸäÿØ"ÿå "ÿ±ÿ≥ÿßŸÑÿ©"

## 4. tasks (ÿßŸÑŸÖŸáÿßŸÖ)
- create_task: ÿ•ÿ∂ÿßŸÅÿ© ŸÖŸáŸÖÿ© ÿ¨ÿØŸäÿØÿ©
- list_tasks: ÿπÿ±ÿ∂ ÿßŸÑŸÖŸáÿßŸÖ
- complete_task: ÿ•ŸÉŸÖÿßŸÑ ŸÖŸáŸÖÿ©
- ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑÿØÿßŸÑÿ©: "ŸÖŸáŸÖÿ©"ÿå "ÿ£ÿ∂ŸÅ ŸÖŸáŸÖÿ©"ÿå "ŸÇÿßÿ¶ŸÖÿ© ÿßŸÑŸÖŸáÿßŸÖ"

## 5. system (ÿßŸÑŸÜÿ∏ÿßŸÖ)
- open_app: ŸÅÿ™ÿ≠ ÿ™ÿ∑ÿ®ŸäŸÇ
- set_volume: ÿßŸÑÿ™ÿ≠ŸÉŸÖ ÿ®ÿßŸÑÿµŸàÿ™
- sleep_display: ÿ•ÿ∑ŸÅÿßÿ° ÿßŸÑÿ¥ÿßÿ¥ÿ©
- ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑÿØÿßŸÑÿ©: "ÿßŸÅÿ™ÿ≠"ÿå "ÿ¥ÿ∫ŸëŸÑ"ÿå "ÿßŸÑÿµŸàÿ™"ÿå "ÿßŸÑÿ¥ÿßÿ¥ÿ©"

## 6. organizer (ÿßŸÑŸÖŸÜÿ∏ŸÖ ÿßŸÑÿ∞ŸÉŸä)
- organize_downloads: ÿ™ÿ±ÿ™Ÿäÿ® ŸÖÿ¨ŸÑÿØ ÿßŸÑÿ™ŸÜÿ≤ŸäŸÑÿßÿ™
- clean_desktop: ÿ™ŸÜÿ∏ŸäŸÅ ÿ≥ÿ∑ÿ≠ ÿßŸÑŸÖŸÉÿ™ÿ®
- ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑÿØÿßŸÑÿ©: "ÿ±ÿ™ÿ® ÿßŸÑÿ™ŸÜÿ≤ŸäŸÑÿßÿ™"ÿå "ŸÜÿ∏ŸÅ ÿ≥ÿ∑ÿ≠ ÿßŸÑŸÖŸÉÿ™ÿ®"ÿå "ŸÅÿ±ÿ≤ ÿßŸÑŸÖŸÑŸÅÿßÿ™"

## 7. secretary (ÿßŸÑÿ≥ŸÉÿ±ÿ™Ÿäÿ± ÿßŸÑÿ™ŸÜŸÅŸäÿ∞Ÿä)
- get_morning_briefing: ÿπÿ±ÿ∂ ÿßŸÑŸÖŸàÿ¨ÿ≤ ÿßŸÑÿµÿ®ÿßÿ≠Ÿä
- set_work_mode: ÿ™ÿ∫ŸäŸäÿ± Ÿàÿ∂ÿπ ÿßŸÑÿπŸÖŸÑ (work, meeting, chill)
- ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑÿØÿßŸÑÿ©: "ÿµÿ®ÿßÿ≠ ÿßŸÑÿÆŸäÿ±"ÿå "Ÿàÿ∂ÿπ ÿßŸÑÿπŸÖŸÑ"ÿå "ÿßÿ¨ÿ™ŸÖÿßÿπ"ÿå "ÿßÿ≥ÿ™ÿ±ÿßÿ≠ÿ©"

## 8. memory_manager (ŸÖÿØŸäÿ± ÿßŸÑÿ∞ÿßŸÉÿ±ÿ©)
- create_project: ÿ•ŸÜÿ¥ÿßÿ° ŸÖÿ¥ÿ±Ÿàÿπ ÿ¨ÿØŸäÿØ
- save_thought: ÿ≠ŸÅÿ∏ ŸÅŸÉÿ±ÿ© ÿ£Ÿà ŸÖŸÑÿßÿ≠ÿ∏ÿ© (ŸÖÿπ ÿ™ŸÑÿÆŸäÿµ ÿ™ŸÑŸÇÿßÿ¶Ÿä)
- search: ÿßŸÑÿ®ÿ≠ÿ´ ŸÅŸä ÿßŸÑÿ∞ÿßŸÉÿ±ÿ© (Semantic Search)
- ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑÿØÿßŸÑÿ©: "ŸÖÿ¥ÿ±Ÿàÿπ ÿ¨ÿØŸäÿØ"ÿå "ŸÅŸÉÿ±ÿ©"ÿå "ÿßÿ≠ŸÅÿ∏"ÿå "ÿØŸàŸÜ"ÿå "ÿßÿ®ÿ≠ÿ´ ŸÅŸä ÿ∞ÿßŸÉÿ±ÿ™Ÿä"ÿå "ŸÖÿßÿ∞ÿß ŸÇŸÑÿ™ ÿπŸÜ"

# ŸÇŸàÿßÿπÿØ ŸÖŸáŸÖÿ©:
1. "ÿßŸÅÿ™ÿ≠ ŸÖÿ¨ŸÑÿØ ÿ¨ÿØŸäÿØ" ÿ£Ÿà "ÿ£ŸÜÿ¥ÿ¶ ŸÖÿ¨ŸÑÿØ" = files.create_folder (ŸÑŸäÿ≥ memory!)
2. "ÿßŸÅÿ™ÿ≠ ÿ™ÿ∑ÿ®ŸäŸÇ" ÿ£Ÿà "ÿ¥ÿ∫ŸëŸÑ ÿ®ÿ±ŸÜÿßŸÖÿ¨" = system.open_app
3. "ÿßÿ≠ŸÅÿ∏ ŸÖŸÑÿßÿ≠ÿ∏ÿ©" ÿ£Ÿà "ÿ≥ÿ¨ŸëŸÑ ŸÅŸÉÿ±ÿ©" = memory_manager.save_thought
4. "ŸÖÿ¥ÿ±Ÿàÿπ ÿ¨ÿØŸäÿØ ÿ®ÿßÿ≥ŸÖ X" = memory_manager.create_project(name='X')
5. "ŸÖÿßÿ∞ÿß ŸÇŸÑÿ™ ÿπŸÜ Xÿü" = memory_manager.search(query='X')
6. "ÿ±ÿ™ÿ® ÿßŸÑÿ™ŸÜÿ≤ŸäŸÑÿßÿ™" = organizer.organize_downloads
7. "ÿµÿ®ÿßÿ≠ ÿßŸÑÿÆŸäÿ±" = secretary.get_morning_briefing
8. "Ÿàÿ∂ÿπ ÿßŸÑÿπŸÖŸÑ" = secretary.set_work_mode(mode='work')
5. "ŸÜÿ∏ŸÅ ÿ≥ÿ∑ÿ≠ ÿßŸÑŸÖŸÉÿ™ÿ®" = organizer.clean_desktop
4. ÿ•ÿ∞ÿß ÿ∞ŸÉÿ± ÿßÿ≥ŸÖ "ŸáŸäÿ´ŸÖ" ÿ£Ÿà "ŸáŸäŸÖ" ŸÉŸÖÿ¨ŸÑÿØ = ŸäŸÇÿµÿØ ŸÖÿ¨ŸÑÿØ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿä ~/
5. **"ÿØÿßÿÆŸÑ" ÿ™ÿπŸÜŸä ŸÖÿ≥ÿßÿ± ŸÖÿ™ÿØÿßÿÆŸÑ:** "ŸÖŸÑŸÅ X ÿØÿßÿÆŸÑ ŸÖÿ¨ŸÑÿØ Y" = "Y/X" (ŸÖŸáŸÖ ÿ¨ÿØÿßŸã!)
   - ŸÖÿ´ÿßŸÑ: "ŸÖŸÑŸÅ ÿßŸÑÿπŸÖŸÑ ÿØÿßÿÆŸÑ ŸÖÿ¨ŸÑÿØ ŸáŸäÿ´ŸÖ" ‚Üí directory: "ŸáŸäÿ´ŸÖ/ÿßŸÑÿπŸÖŸÑ"
   - ŸÖÿ´ÿßŸÑ: "ŸÖÿ¨ŸÑÿØ ÿßŸÑŸÖŸáÿßŸÖ ÿØÿßÿÆŸÑ ÿßŸÑÿ™ŸÜÿ≤ŸäŸÑÿßÿ™" ‚Üí directory: "~/Downloads/ÿßŸÑŸÖŸáÿßŸÖ"

# ÿ£ŸÖÿ´ŸÑÿ©:

ŸÖÿ´ÿßŸÑ 1:
ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ: "ÿßŸÅÿ™ÿ≠ ŸÖÿ¨ŸÑÿØ ÿ¨ÿØŸäÿØ ÿØÿßÿÆŸÑ ŸÖÿ¨ŸÑÿØ ŸáŸäÿ´ŸÖ ÿ®ÿßÿ≥ŸÖ ÿßŸÑŸÖŸáÿßŸÖ"
{
    "intent": "ÿ•ŸÜÿ¥ÿßÿ° ŸÖÿ¨ŸÑÿØ ÿ¨ÿØŸäÿØ ÿ®ÿßÿ≥ŸÖ ÿßŸÑŸÖŸáÿßŸÖ ÿØÿßÿÆŸÑ ÿßŸÑŸÖÿ¨ŸÑÿØ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿä",
    "tool": "files",
    "action": "create_folder",
    "parameters": {
        "directory": "ŸáŸäÿ´ŸÖ/ÿßŸÑŸÖŸáÿßŸÖ"
    },
    "confirmation_needed": false
}

ŸÖÿ´ÿßŸÑ 2:
ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ: "ÿßŸÅÿ™ÿ≠ ŸÖŸÑŸÅ ÿ¨ÿØŸäÿØ ÿ®ÿßÿ≥ŸÖ ÿßŸÑÿπŸÖŸÑ ÿØÿßÿÆŸÑ ŸÖÿ¨ŸÑÿØ ŸáŸäÿ´ŸÖ"
{
    "intent": "ÿ•ŸÜÿ¥ÿßÿ° ŸÖŸÑŸÅ ÿßŸÑÿπŸÖŸÑ ÿØÿßÿÆŸÑ ŸÖÿ¨ŸÑÿØ ŸáŸäÿ´ŸÖ",
    "tool": "files",
    "action": "create_folder",
    "parameters": {
        "directory": "ŸáŸäÿ´ŸÖ/ÿßŸÑÿπŸÖŸÑ"
    },
    "confirmation_needed": false
}

ŸÖÿ´ÿßŸÑ 3:
ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ: "ÿ£ŸÜÿ¥ÿ¶ ŸÖÿ¨ŸÑÿØÿßŸã ÿ¨ÿØŸäÿØÿßŸã ÿ®ÿßÿ≥ŸÖ ÿßŸÑŸÖÿ¥ÿßÿ±Ÿäÿπ ŸÅŸä ÿßŸÑÿ™ŸÜÿ≤ŸäŸÑÿßÿ™"
{
    "intent": "ÿ•ŸÜÿ¥ÿßÿ° ŸÖÿ¨ŸÑÿØ ÿßŸÑŸÖÿ¥ÿßÿ±Ÿäÿπ ŸÅŸä Downloads",
    "tool": "files",
    "action": "create_folder",
    "parameters": {
        "directory": "~/Downloads/ÿßŸÑŸÖÿ¥ÿßÿ±Ÿäÿπ"
    },
    "confirmation_needed": false
}

ŸÖÿ´ÿßŸÑ 4:
ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ: "ÿ¥ÿ∫ŸëŸÑ ŸÖÿ™ÿµŸÅÿ≠ ŸÉÿ±ŸàŸÖ"
{{
    "intent": "ŸÅÿ™ÿ≠ ŸÖÿ™ÿµŸÅÿ≠ Google Chrome",
    "tool": "system",
    "action": "open_app",
    "parameters": {{
        "app_name": "Google Chrome"
    }},
    "confirmation_needed": false
}}

ŸÖÿ´ÿßŸÑ 4:
ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ: "ÿßÿ≠ŸÅÿ∏ Ÿáÿ∞Ÿá ÿßŸÑŸÅŸÉÿ±ÿ©: ŸÜÿ≠ÿ™ÿßÿ¨ ÿ•ŸÑŸâ ÿ™ÿ≠ÿ≥ŸäŸÜ Ÿàÿßÿ¨Ÿáÿ© ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ"
{{
    "intent": "ÿ≠ŸÅÿ∏ ŸÅŸÉÿ±ÿ© ÿπŸÜ ÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑŸàÿßÿ¨Ÿáÿ©",
    "tool": "memory",
    "action": "save_note",
    "parameters": {{
        "content": "ŸÜÿ≠ÿ™ÿßÿ¨ ÿ•ŸÑŸâ ÿ™ÿ≠ÿ≥ŸäŸÜ Ÿàÿßÿ¨Ÿáÿ© ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ"
    }},
    "confirmation_needed": false
}}

ŸÖÿ´ÿßŸÑ 5:
ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ: "ÿßÿπÿ±ÿ∂ ÿßŸÑŸÖŸÑŸÅÿßÿ™ ÿßŸÑŸÖŸàÿ¨ŸàÿØÿ© ŸÅŸä ŸÖÿ¨ŸÑÿØ ÿßŸÑÿ™ÿ∑ŸàŸäÿ±"
{{
    "intent": "ÿπÿ±ÿ∂ ŸÖŸÑŸÅÿßÿ™ ŸÖÿ¨ŸÑÿØ development",
    "tool": "files",
    "action": "list_files",
    "parameters": {{
        "directory": "~/development"
    }},
    "confirmation_needed": false
}}

ŸÖÿ´ÿßŸÑ 6:
ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ: "ÿ£ÿ∂ŸÅ ŸÖŸáŸÖÿ©: ÿßŸÑÿßÿ™ÿµÿßŸÑ ÿ®ÿßŸÑÿπŸÖŸäŸÑ ÿ∫ÿØÿßŸã"
{{
    "intent": "ÿ•ÿ∂ÿßŸÅÿ© ŸÖŸáŸÖÿ© ŸÑŸÑÿßÿ™ÿµÿßŸÑ ÿ®ÿßŸÑÿπŸÖŸäŸÑ",
    "tool": "tasks",
    "action": "create_task",
    "parameters": {{
        "title": "ÿßŸÑÿßÿ™ÿµÿßŸÑ ÿ®ÿßŸÑÿπŸÖŸäŸÑ",
        "due_date": "tomorrow"
    }},
    "confirmation_needed": false
}}

ŸÖÿ´ÿßŸÑ 7:
ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ: "ÿßÿ®ÿ≠ÿ´ ÿπŸÜ ŸÖŸÑŸÅ main.py ŸÅŸä ŸÖÿ¨ŸÑÿØ ÿßŸÑÿ™ÿ∑ŸàŸäÿ±"
{{
    "intent": "ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÜ ŸÖŸÑŸÅ main.py",
    "tool": "files",
    "action": "search_files",
    "parameters": {{
        "directory": "~/development",
        "pattern": "main.py"
    }},
    "confirmation_needed": false
}}

ŸÖÿ´ÿßŸÑ 8:
ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ: "ÿßŸÇÿ±ÿ£ ÿ¢ÿÆÿ± ÿ®ÿ±ŸäÿØ ÿ•ŸÑŸÉÿ™ÿ±ŸàŸÜŸä"
{{
    "intent": "ŸÇÿ±ÿßÿ°ÿ© ÿ¢ÿÆÿ± ÿ®ÿ±ŸäÿØ Ÿàÿßÿ±ÿØ",
    "tool": "gmail",
    "action": "fetch_email",
    "parameters": {{}},
    "confirmation_needed": false
}}

# ÿßŸÑÿ¢ŸÜ ÿ≠ŸÑŸÑ ÿ£ŸÖÿ± ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ Ÿàÿ£ÿ±ÿ¨ÿπ JSON ŸÅŸÇÿ∑:
"""

        response = await self.llm_router.generate_with_gpt(
            prompt,
            temperature=0.1,  # Lower temperature for more consistent parsing
            response_format="json_object"
        )
        
        try:
            if isinstance(response, str):
                clean = response.replace("```json", "").replace("```", "").strip()
                return json.loads(clean)
            return response
        except:
            return {"intent": "Unknown", "tool": "other", "confirmation_needed": False}

    def confirm_plan(self, plan: dict) -> bool:
        """Ask user for confirmation"""
        intent = plan.get("intent", "Unknown")
        self.speak(f"ÿ≥ÿ£ŸÇŸàŸÖ ÿ®ŸÄ: {intent}. ŸÖŸàÿßŸÅŸÇÿü" if self.language == "ar" else f"I will: {intent}. Confirm?")
        
        # Listen for simple yes/no
        response = self.stt.listen_realtime(language=self.language)
        if not response:
            return False
            
        affirmative = ["ŸÜÿπŸÖ", "ŸÖŸàÿßŸÅŸÇ", "ÿ™ŸÖÿßŸÖ", "yes", "ok", "sure"]
        return any(w in response.lower() for w in affirmative)

    async def execute_plan(self, plan: dict) -> dict:
        """Execute the planned action"""
        tool = plan.get("tool")
        action = plan.get("action")
        params = plan.get("parameters", {})
        
        # --- Safety Check (Advisor) ---
        advisor = get_advisor()
        validation = advisor.validate_action(tool, action, params)
        if not validation["safe"]:
            return {"success": False, "message": validation["warning"]}
        # ------------------------------
        
        if tool == "memory":
            if action == "save_note":
                content = params.get("content") or plan.get("intent")
                return await self.memory_tools.process_voice_note(content)
            elif action == "search":
                query = params.get("query") or plan.get("intent")
                res = await self.memory_tools.search_memory_voice(query, language=self.language)
                return {"success": True, "message": res}
                
        elif tool == "gmail":
            if action == "fetch_email":
                email = self.gmail.fetch_latest_email()
                if email:
                    return {"success": True, "message": f"Email from {email['from']}: {email['subject']}"}
                return {"success": False, "message": "No emails found"}
        
        elif tool == "tasks":
            if action == "create_task":
                title = params.get("title") or plan.get("intent")
                project = params.get("project_id", "inbox")
                t = task_manager.create_task(title=title, project_id=project, language=self.language)
                return {"success": True, "message": f"Task created in {project}" if self.language == "en" else f"ÿ™ŸÖ ÿ•ÿ∂ÿßŸÅÿ© ÿßŸÑŸÖŸáŸÖÿ© ŸÅŸä {project}"}
            
            elif action == "list_tasks":
                tasks = task_manager.list_tasks(status="open")
                if not tasks:
                    return {"success": True, "message": "No open tasks" if self.language == "en" else "ŸÑÿß ŸäŸàÿ¨ÿØ ŸÖŸáÿßŸÖ ŸÖŸÅÿ™Ÿàÿ≠ÿ©"}
                msg = f"Found {len(tasks)} tasks. " + ", ".join([t.title for t in tasks[:3]])
                return {"success": True, "message": msg}
                
            elif action == "complete_task":
                # This is tricky without ID. We need to find by title similarity.
                # For now, just say not implemented fully via voice without ID context.
                # Or try to match title.
                title = params.get("title")
                if title:
                    # Simple fuzzy match
                    tasks = task_manager.list_tasks(status="open")
                    for t in tasks:
                        if title.lower() in t.title.lower():
                            task_manager.complete_task(t.id, t.project_id or "inbox")
                            return {"success": True, "message": f"Completed task: {t.title}"}
                return {"success": False, "message": "Task not found"}

        elif tool == "files":
            directory = self._resolve_path(params.get("directory", "~"))
            
            if action == "list_files":
                res = await self.file_tools.list_files(directory)
                if res.get("error"):
                    return {"success": False, "message": res["message"]}
                
                files = res["files"]
                if not files:
                    return {"success": True, "message": "No files found" if self.language == "en" else "ŸÑÿß ŸäŸàÿ¨ÿØ ŸÖŸÑŸÅÿßÿ™"}
                
                # Format output
                count = res["count"]
                msg = f"Found {count} files in {directory}. " if self.language == "en" else f"Ÿàÿ¨ÿØÿ™ {count} ŸÖŸÑŸÅÿßÿ™ ŸÅŸä {directory}. "
                # List first 5 names
                names = [f["name"] for f in files[:5]]
                msg += ", ".join(names)
                if count > 5:
                    msg += "..."
                return {"success": True, "message": msg}
                
            elif action == "search_files":
                pattern = params.get("pattern") or params.get("query") or "*"
                res = await self.file_tools.search_files(directory, pattern)
                if res.get("error"):
                    return {"success": False, "message": res["message"]}
                
                matches = res["matches"]
                if not matches:
                    return {"success": True, "message": "No matches found" if self.language == "en" else "ŸÑŸÖ ÿ£ÿ¨ÿØ ÿ£Ÿä ŸÖŸÑŸÅÿßÿ™"}
                
                count = res["count"]
                msg = f"Found {count} matches. " if self.language == "en" else f"Ÿàÿ¨ÿØÿ™ {count} ŸÖŸÑŸÅÿßÿ™. "
                names = [f["name"] for f in matches[:5]]
                msg += ", ".join(names)
                return {"success": True, "message": msg}
                
            elif action == "create_folder":
                # Handle nested paths: "folder X inside folder Y"
                # The LLM should ideally give us "Y/X" in the directory param.
                raw_dir = params.get("directory", "")
                
                # If the path already starts with ~/ or /, use it as-is
                if raw_dir.startswith("~/") or raw_dir.startswith("/"):
                    full_path = raw_dir
                else:
                    # Split and resolve
                    parts = raw_dir.split("/")
                    base = self._resolve_path(parts[0])
                    
                    if len(parts) > 1:
                        # If base already contains the first part (e.g. "~/Downloads"),
                        # just append the rest
                        full_path = f"{base}/{'/'.join(parts[1:])}"
                    else:
                        full_path = base
                    
                res = await self.file_tools.create_folder(full_path)
                if res.get("error"):
                    return {"success": False, "message": res["message"]}
                
                return {"success": True, "message": f"Created folder: {full_path}" if self.language == "en" else f"ÿ™ŸÖ ÿ•ŸÜÿ¥ÿßÿ° ÿßŸÑŸÖÿ¨ŸÑÿØ: {full_path}"}

        elif tool == "system":
            if action == "open_app":
                app = params.get("app_name") or plan.get("intent")
                # Clean up intent if it contains "open"
                app = app.replace("open ", "").replace("ÿßŸÅÿ™ÿ≠ ", "").replace("ÿ¥ÿ∫ŸÑ ", "")
                return await self.system_tools.open_app(app)
            
            elif action == "set_volume":
                level = params.get("level")
                if level is None:
                    # Try to parse from intent
                    import re
                    nums = re.findall(r'\d+', plan.get("intent", ""))
                    if nums:
                        level = int(nums[0])
                    else:
                        # Default increments?
                        if "up" in plan.get("intent", "") or "ÿßÿ±ŸÅÿπ" in plan.get("intent", ""):
                            return await self.system_tools.set_volume(50) # TODO: get current and +10
                        elif "down" in plan.get("intent", "") or "Ÿàÿ∑Ÿä" in plan.get("intent", ""):
                            return await self.system_tools.set_volume(20)
                        else:
                            level = 50
                return await self.system_tools.set_volume(int(level))
                
        elif tool == "organizer":
            organizer = get_organizer()
            
            if action == "organize_downloads":
                res = organizer.organize_downloads()
                if "error" in res:
                    return {"success": False, "message": res["error"]}
                    
                # Format report
                msg = f"Downloads Organized.\nTotal Moved: {res['total_moved']}\n"
                for cat, count in res["categories"].items():
                    msg += f"- {cat}: {count}\n"
                return {"success": True, "message": msg, "data": msg} # data for GUI
                
            elif action == "clean_desktop":
                res = organizer.clean_desktop()
                msg = f"Desktop Cleaned.\nTotal Moved: {res['total_moved']}\n"
                if res["screenshots_moved"] > 0:
                    msg += f"- Screenshots: {res['screenshots_moved']}\n"
                if res["misc_moved"] > 0:
                    msg += f"- Misc Files: {res['misc_moved']}\n"
                    msg += f"Moved to: {Path(res['dest_folder']).name}"
                return {"success": True, "message": msg, "data": msg}

        elif tool == "secretary":
            secretary = get_secretary()
            
            if action == "get_morning_briefing":
                res = await secretary.get_morning_briefing()
                # Return data for GUI to render nicely
                return {"success": True, "message": res["text"], "data": res["text"]}
                
            elif action == "set_work_mode":
                mode = params.get("mode") or plan.get("intent")
                msg = await secretary.set_work_mode(mode)
                return {"success": True, "message": msg, "data": msg}
            
            elif action == "mute":
                return await self.system_tools.mute_volume()
                
        elif tool == "memory_manager":
            manager = get_memory_manager()
            
            if action == "create_project":
                name = params.get("name") or plan.get("intent")
                desc = params.get("description", "")
                res = manager.create_project(name, desc)
                return res
                
            elif action == "save_thought":
                content = params.get("content") or plan.get("intent")
                project = params.get("project_name")
                res = await manager.save_thought(content, project)
                
                if res["success"]:
                    # Format nice message with summary
                    msg = f"Saved thought.\nSummary: {res.get('summary')}"
                    return {"success": True, "message": msg, "data": msg}
                return res

            elif action == "search":
                query = params.get("query") or plan.get("intent")
                results = await manager.search_memory(query)
                
                if not results:
                    return {"success": True, "message": "No relevant memories found.", "data": "No results."}
                
                msg = f"üîç **Memory Search Results for '{query}'**\n\n"
                for r in results:
                    content = r['content'][:200].replace("\n", " ") + "..."
                    msg += f"- {content}\n"
                    
                return {"success": True, "message": msg, "data": msg}

            
            elif action == "unmute":
                return await self.system_tools.unmute_volume()
                
            elif action == "sleep_display":
                return await self.system_tools.sleep_display()

        return {"success": False, "message": "Unknown action"}

    def _speak_result(self, result: dict):
        """Speak the execution result"""
        msg = result.get("message", "Done")
        self.speak(msg)

    async def run(self):
        """Main Loop"""
        logger.info("HVA Running. Press Ctrl+C to exit.")
        self.speak("ÿ£ŸÜÿß ÿ¨ÿßŸáÿ≤" if self.language == "ar" else "I am ready")
        
        try:
            while self.is_running:
                # In a real GUI/Voice app, we'd have a wake word.
                # Here we loop, but we need a trigger.
                # For this CLI version, we'll prompt user to press Enter to listen
                # to avoid infinite loop of silence processing.
                print("\nPress ENTER to speak (or Ctrl+C to exit)...")
                await asyncio.get_event_loop().run_in_executor(None, sys.stdin.readline)
                
                await self.process_command_mode()
                
        except KeyboardInterrupt:
            logger.info("Exiting...")
            self.speak("ŸÖÿπ ÿßŸÑÿ≥ŸÑÿßŸÖÿ©" if self.language == "ar" else "Goodbye")


async def main():
    parser = argparse.ArgumentParser(description="Haitham Voice Agent")
    parser.add_argument("--test", type=str, help="Run a text command without voice")
    args = parser.parse_args()
    
    hva = HVA()
    await hva.initialize_async()
    
    if args.test:
        logger.info(f"Test Mode: {args.test}")
        await hva.process_text_command(args.test)
    else:
        await hva.run()

if __name__ == "__main__":
    asyncio.run(main())
