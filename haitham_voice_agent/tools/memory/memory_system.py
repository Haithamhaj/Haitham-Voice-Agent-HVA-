import logging
import uuid
from datetime import datetime
from typing import List, Optional, Dict, Any, Union

from .models.memory import Memory, MemoryType, MemorySource, SensitivityLevel
from .storage.sqlite_store import SQLiteStore
from .storage.vector_store import VectorStore
from .intelligence.classifier import SmartClassifier
from .intelligence.summarizer import Summarizer
from .utils.embeddings import EmbeddingGenerator

logger = logging.getLogger(__name__)

class MemorySystem:
    """
    Main entry point for the Advanced Memory System.
    Coordinates input processing, intelligence, storage, and retrieval.
    """
    
    def __init__(self):
        self.sqlite_store = SQLiteStore()
        self.vector_store = VectorStore()
        self.classifier = SmartClassifier()
        self.summarizer = Summarizer()
        self.embedding_generator = EmbeddingGenerator()
        
    async def initialize(self):
        """Initialize storage systems"""
        await self.sqlite_store.initialize()
        
    async def add_memory(
        self, 
        content: str, 
        source: Union[MemorySource, str] = MemorySource.MANUAL,
        context: Optional[str] = None
    ) -> Optional[Memory]:
        """
        Process and store a new memory
        """
        try:
            # 1. Generate Embedding
            embedding = await self.embedding_generator.generate(content)
            
            # 2. Classify
            classification = await self.classifier.classify(content, context)
            
            # 3. Summarize
            summary = await self.summarizer.summarize(content)
            
            # 4. Create Memory Object
            memory_id = str(uuid.uuid4())
            timestamp = datetime.now()
            
            # Handle source enum
            if isinstance(source, str):
                try:
                    source_enum = MemorySource(source.lower())
                except ValueError:
                    source_enum = MemorySource.MANUAL
            else:
                source_enum = source
            
            # Handle type enum
            try:
                type_enum = MemoryType(classification.get("type", "note").lower())
            except ValueError:
                type_enum = MemoryType.NOTE
                
            memory = Memory(
                id=memory_id,
                timestamp=timestamp,
                source=source_enum,
                project=classification.get("project", "General"),
                topic=classification.get("topic", "Unclassified"),
                type=type_enum,
                tags=classification.get("tags", []),
                ultra_brief=summary.get("ultra_brief", ""),
                executive_summary=summary.get("executive_summary", []),
                detailed_summary=summary.get("detailed_summary", ""),
                raw_content=content,
                decisions=summary.get("decisions", []),
                action_items=summary.get("action_items", []),
                open_questions=summary.get("open_questions", []),
                key_insights=summary.get("key_insights", []),
                people_mentioned=summary.get("people_mentioned", []),
                projects_mentioned=summary.get("projects_mentioned", []),
                language="en", # TODO: Detect language
                sentiment=classification.get("sentiment", "neutral"),
                importance=classification.get("importance", 3),
                confidence=classification.get("confidence", 1.0),
                sensitivity=SensitivityLevel.PRIVATE,
                embedding=embedding
            )
            
            # 5. Save to SQLite
            await self.sqlite_store.save_memory(memory)
            
            # 6. Save to Vector Store
            metadata = {
                "project": memory.project,
                "topic": memory.topic,
                "type": memory.type.value,
                "timestamp": memory.timestamp.isoformat()
            }
            self.vector_store.add_embedding(memory_id, embedding, metadata)
            
            logger.info(f"Memory stored: {memory_id} ({memory.project} - {memory.topic})")
            return memory
            
        except Exception as e:
            logger.error(f"Failed to add memory: {e}")
            return None

    async def search_memories(
        self, 
        query: str, 
        limit: int = 5,
        project: Optional[str] = None
    ) -> List[Memory]:
        """
        Semantic search for memories
        """
        try:
            # 1. Generate query embedding
            query_embedding = await self.embedding_generator.generate(query)
            
            # 2. Search Vector Store
            filter_criteria = {}
            if project:
                filter_criteria["project"] = project
                
            vector_results = self.vector_store.search(
                query_embedding, 
                limit=limit,
                filter_criteria=filter_criteria if filter_criteria else None
            )
            
            # 3. Retrieve full objects from SQLite
            memories = []
            for result in vector_results:
                memory_id = result["id"]
                memory = await self.sqlite_store.get_memory(memory_id)
                if memory:
                    memories.append(memory)
            
            return memories
            
        except Exception as e:
            logger.error(f"Search failed: {e}")
            return []

    async def delete_memory(self, memory_id: str) -> bool:
        """Delete memory from all stores"""
        try:
            sqlite_success = await self.sqlite_store.delete_memory(memory_id)
            vector_success = self.vector_store.delete_embedding(memory_id)
            return sqlite_success and vector_success
        except Exception as e:
            logger.error(f"Failed to delete memory {memory_id}: {e}")
            return False

    async def index_file(self, path: str, project_id: str, description: str = "", tags: List[str] = None) -> bool:
        """
        Index a file in the memory system.
        Generates an embedding for the description/content to allow semantic search.
        """
        try:
            # Generate embedding for description + tags
            content_to_embed = f"{description} {' '.join(tags or [])}"
            embedding = await self.embedding_generator.generate(content_to_embed)
            
            # Store embedding in Vector Store (using path as ID, or a hash)
            # Using path as ID might be tricky if path changes, but for now it's the PK
            # Let's use a deterministic hash of the path as the vector ID
            import hashlib
            vector_id = hashlib.md5(path.encode()).hexdigest()
            
            metadata = {
                "type": "file",
                "project": project_id,
                "path": path,
                "timestamp": datetime.now().isoformat()
            }
            self.vector_store.add_embedding(vector_id, embedding, metadata)
            
            # Store in SQLite File Index
            return await self.sqlite_store.index_file(path, project_id, description, tags, vector_id)
            
        except Exception as e:
            logger.error(f"Failed to index file {path}: {e}")
            return False

    async def search_files(self, query: str, project_id: Optional[str] = None, limit: int = 5) -> List[Dict[str, Any]]:
        """
        Search for files using semantic search + text match
        """
        try:
            # 1. Semantic Search via Vector Store
            query_embedding = await self.embedding_generator.generate(query)
            filter_criteria = {"type": "file"}
            if project_id:
                filter_criteria["project"] = project_id
                
            vector_results = self.vector_store.search(query_embedding, limit=limit, filter_criteria=filter_criteria)
            
            # 2. Retrieve details from SQLite File Index
            results = []
            seen_paths = set()
            
            # Add vector results
            for res in vector_results:
                path = res["metadata"].get("path")
                if path and path not in seen_paths:
                    file_data = await self.sqlite_store.get_file_index(path)
                    if file_data:
                        file_data["score"] = res["score"]
                        results.append(file_data)
                        seen_paths.add(path)
            
            # 3. Fallback/Augment with Text Search (if few results)
            if len(results) < limit:
                text_results = await self.sqlite_store.search_file_index(query)
                for res in text_results:
                    if res["path"] not in seen_paths:
                        res["score"] = 0.5 # Arbitrary score for text match
                        results.append(res)
                        seen_paths.add(res["path"])
                        
            return results[:limit]
            
        except Exception as e:
            logger.error(f"File search failed: {e}")
            return []
